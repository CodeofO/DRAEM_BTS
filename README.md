# DRAEM : A discriminatively trained reconstruction embedding for surface anomaly detection

Topic: ê²°í•¨ íƒì§€, ì»´í“¨í„° ë¹„ì „
Year: 2021

[](https://openaccess.thecvf.com/content/ICCV2021/papers/Zavrtanik_DRAEM_-_A_Discriminatively_Trained_Reconstruction_Embedding_for_Surface_Anomaly_ICCV_2021_paper.pdf)

# 0. Abstract

***Recent surface anomaly detection methods***

â‡’ *generative models* 

1. *to accurately reconstruct the normal areas*
2. to *fail on anomalies*

*we cast surface anomaly detection primarily as a discriminative problem*

and *propose a `**discriminatively trained reconstruction anomaly embedding model**` (DRÃ†M)*

***DRÃ†M learn the contents below***

1. *a joint representation of an anomalous image*
2. *its anomaly-free reconstruction*
3. *a decision boundary between normal and anomalous examples*

***The method enables the contents below***

1. *direct anomaly localization without the need for additional complicated post-processing of the network output*
2. *can be trained using simple and general anomaly simulations*

[https://github.com/VitjanZ/DRAEM](https://github.com/VitjanZ/DRAEM)

# 1. Introduce

**general anomaly detection problem**

â‡’ considers anomalies asÂ *`entire images`*Â that significantly differ from the non-anomalous training set images

**surface anomaly detection problems(ours)**

â‡’ the anomalies occupy onlyÂ *`a small fraction*Â of image` pixels and are typically close to the training set distribution

### Reconstructive Methods

Reconstructive methods, such as Autoencoders [5, 1, 2, 26] and GANs [24, 23], have been extensively explored since they enable learning of `a powerful reconstruction` subspace, using `only anomaly-free images.`

Relying on poor re-construction capability of anomalous regions, not observed in training,

the anomalies can then be detected `by thresholding the difference between the input image` and `its reconstruction.`

**Issue**

determining the presence of anomalies that are not substantially different from normal appear- ance remains challenging, since these are `often well reconstructed`.

**Recent improvements**

1. **The difference**
by thresholding the difference between `the input image` and `its reconstruction.`
    
    â‡’ the difference between `deep features extracted from a general-purpose network` and `a network specialized for anomaly-free images`
    
2. **Discrimination**
: Discrimination can also be formulated as a `deviation from a dense clustering of non-anomalous textures` within the deep subspace
    
    <aside>

    **ğŸ’¡ the deep subspace** : as forming such a compact subspace `prevents anomalies from being mapped close to anomaly-free samples.`
    </aside>
    

### Hypothesis

We hypothesize that over-fitting can be substantially reduced `by training a discriminative model over the joint, reconstructed and original, appearance` along with the `reconstruction subspace`.

ê°„ë‹¨íˆ ë§í•´, ëª¨ë¸ì€ ì›ë˜ ë°ì´í„°ì™€ ê·¸ ë°ì´í„°ì˜ ì¬êµ¬ì„± ë²„ì „ ì‚¬ì´ì˜ 'ê±°ë¦¬'ë¥¼ í•™ìŠµí•˜ì—¬, ì´ë¥¼ í†µí•´ ì‹¤ì œ ì„¸ê³„ì—ì„œ ë‹¤ì–‘í•œ ì´ìƒ í˜„ìƒì„ ë” ì˜ ì´í•´í•˜ê³  ë¶„ë¥˜í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ëª¨ë¸ì´ í•©ì„± ë°ì´í„°ì— ê³¼ì í•©ë˜ëŠ” ë¬¸ì œë¥¼ í”¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

# 2. Related work

> Instead of the commonly used image space reconstruction, the reconstruction of pretrained network features `can also be used for surface anomaly detection`
> 
> 
> [Unsupervised anomaly segmentation via deep feature reconstruction](https://www.sciencedirect.com/science/article/abs/pii/S0925231220317951)
> 
> [](https://openaccess.thecvf.com/content_CVPR_2020/papers/Bergmann_Uninformed_Students_Student-Teacher_Anomaly_Detection_With_Discriminative_Latent_Embeddings_CVPR_2020_paper.pdf)
> 
> Anomalies are detected based on the assumption that features of a pre-trained network will not be faithfully reconstructued by another network trained only on anomaly-free images.
> 
> ë¹„ì •ìƒë“¤ì€ ì‚¬ì „í•™ìŠµëœ networkì˜ í”¼ì³ë“¤ì´ anomaly-free ì´ë¯¸ì§€ë“¤ë¡œë§Œ í•™ìŠµëœ ë‹¤ë¥¸ networkë¡œë¶€í„° ì •í™•í•˜ê²Œ ì¬êµ¬ì„±ë˜ì§€ ì•Šì„ ê²ƒì´ë¼ëŠ” ê°€ì •ì— ê¸°ë°˜í•˜ì—¬ íƒì§€ëœë‹¤. 
> 

> Recently `Patch-based one-class classification methods` have been considered for surface anomaly detection.
> 

â€¦

# 3. DREAM
![Untitled](https://github.com/CodeofO/DRAEM_BTS/assets/99871109/54277cb9-8f0e-47a4-a284-2bafb8b7351a)
<br>
The anomaly detection process of the proposed method

## 1) **The reconstructive Sub network**
![Untitled 1](https://github.com/CodeofO/DRAEM_BTS/assets/99871109/9683bc64-e4ce-432a-b5f6-8029f27fce1b)
<br>
The reconstructive sub-network is trained to implicitly detect and reconstruct the anomalies with semantically plausible anomaly-free content, while keeping the non-anomalous regions of the input image unchanged.

| $I$ | original image |
| --- | --- |
| $I_a$ | an artificially corrupted version |

### **Loss**

1. **SSIM(Structural Similrity Index) loss**
    - ì£¼ì–´ì§„ 2ê°œì˜ ì´ë¯¸ì§€ì˜Â `similarity(ìœ ì‚¬ë„)`ë¥¼ ê³„ì‚°í•˜ëŠ” ì¸¡ë„ë¡œ ì‚¬ìš©
    - `SSIM`ì€ ë‘ ì´ë¯¸ì§€ì˜ ë‹¨ìˆœ ìœ ì‚¬ë„ë¥¼ ì¸¡ì •í•˜ëŠ”ë° ì‚¬ìš©
    - ë‘ ì´ë¯¸ì§€ê°€ ìœ ì‚¬í•´ì§€ë„ë¡ ë§Œë“¤ì–´ì•¼ ë˜ëŠ” ë¬¸ì œì¼ ë•ŒÂ `SSIM`ì„ Loss Function í˜•íƒœë¡œ ì‚¬ìš©í•˜ê¸°ë„ í•©ë‹ˆë‹¤. ì™œëƒí•˜ë©´Â `SSIM`ì´ gradient-basedë¡œ êµ¬í˜„ë˜ì–´ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
    ![Untitled 2](https://github.com/CodeofO/DRAEM_BTS/assets/99871109/b65fc501-610e-441f-8a4c-11045f699d74)
    <br>

    | $H, W$ | ì´ë¯¸ì§€ $I$ì˜ ë†’ì´ ë„“ì´ |
    | --- | --- |
    | $N_p$ | ì´ë¯¸ì§€ $I$ì˜ pixel ìˆ˜ |
    | $I_r$ | reconstructed  $I$(output) |
    | $SSIM(I, I_r)_{(i, j)}$ | SSIM value for patch of $I$ and $I_r$ |
2. **The reconstruction loss**
    ![Untitled 3](https://github.com/CodeofO/DRAEM_BTS/assets/99871109/3cf67455-443e-496c-8248-73edd1e59fbe)
    <br>
    
    | $\lambda$ | loss balancing hyper-parameter |
    | --- | --- |

### **Summary**

1. **Train**
    
    
    | Input / Target | noise ì²˜ë¦¬ëœ ì •ìƒ   /   raw ì •ìƒ |
    | --- | --- |
    | Output | reconstructed ëœ ì •ìƒ |
    | What is trained | noise(ê°€ìƒê²°í•¨)ì„ ì •ìƒìœ¼ë¡œ ë³µì›í•˜ëŠ” ê²ƒ |
    | Evaluate cost<br>(L2 + SSIM loss) | reconstruction loss(Targetê³¼ Outputìœ¼ë¡œ ê³„ì‚°ë¨)<br>ğŸ‘‰ ìµœì†Œí™” í•˜ëŠ” ê²ƒì´ ëª©í‘œ |
2. **Classification** 
    
    
    | input | raw ë¹„ì •ìƒ |
    | --- | --- |
    | output | ì •ìƒìœ¼ë¡œ reconstructed ëœ ë¹„ì •ìƒ |
    | Classification | anomaliesë¥¼ ì •ìƒë¶€ìœ„ë¡œ ë°”ê¿ˆìœ¼ë¡œì„œ<br>ğŸ‘‰ reconstruction loss ë†’ì•„ì§<br>ğŸ‘‰ ê²°í•¨ íŒë³„ |
    

## 2) **The discriminative sub-network**
![Untitled 4](https://github.com/CodeofO/DRAEM_BTS/assets/99871109/a857b46a-2a86-4feb-8c3a-4cbe45ed352d)

the discriminative sub-network learns a joint reconstruction-anomaly embedding and produces accurate anomaly segmentation maps from the concatenated reconstructed and original appearance.

ì •ìƒìœ¼ë¡œ ë³µì›í•˜ëŠ” The reconstruction networkì˜ íŠ¹ì§• ë•Œë¬¸ì—

- Anomalous imagesì˜ $I_r$ì€ $I$ì™€ í¬ê²Œ ì°¨ì´ ë‚œë‹¤.
- ê·¸ë¦¬ê³  anomaly segmentationì— í•„ìˆ˜ì ì¸ ì •ë³´ë¥¼ ì œê³µí•¨

| Input  | $I_c$ : $I_r$ ê³¼ $I$ì˜ ì±„ë„ë³„ concatenation |
| --- | --- |
| Output | $M_o$ : a pixel-level anomaly detection mask |

### Loss : focal loss

Focal Loss($L_{seg}$) is applied on the discriminative sub-network output `to increase robustness towards accurate segmentation` of hard examples.

`Focal Loss`ëŠ”Â Easy Exampleì˜ weightë¥¼ ì¤„ì´ê³  `Hard Negative Example`ì— ëŒ€í•œ í•™ìŠµì— ì´ˆì ì„ ë§ì¶”ëŠ” Cross Entropy Loss í•¨ìˆ˜ì˜ í™•ì¥íŒì´ë‹¤.

ğŸ‘‰  data imbalanceing
![Untitled 5](https://github.com/CodeofO/DRAEM_BTS/assets/99871109/21b032b7-a705-43f6-a1a9-441ac2ee3189)

| $\alpha$ | ì „ì²´ì ì¸ Loss ê°’ì„ ì¡°ì ˆí•˜ëŠ” ê°’ |
| --- | --- |
| $(1 - p_t)^\gamma$ | $\gamma \geq 0$ ì˜ ê°’ì„ ì¡°ì ˆí•´ì•¼ ì¢‹ì€ ì„±ëŠ¥ ì–»ì„ ìˆ˜ ìˆìŒ |
| $\gamma$ | focusing parameter,<br>Easy Exampleì— ëŒ€í•œ Lossì˜ ë¹„ì¤‘ì„ ë‚®ì¶”ëŠ” ì—­í•  |
<br>

![Untitled 6](https://github.com/CodeofO/DRAEM_BTS/assets/99871109/8491e80f-7c5a-46b4-83b1-eacecd3af74a)

<br>

$\lambda = 0$ : Cross entropy lossì™€ ê°™ìŒ

### Total Loss
![Untitled 7](https://github.com/CodeofO/DRAEM_BTS/assets/99871109/38e6dfa4-309f-4243-90af-6bc181562554)
<br>

| $M_a$ | ground truth |
| --- | --- |
| $M$ | output segmentation masks |

## 3) Simulated anomaly generation

### A noise image
![Untitled 8](https://github.com/CodeofO/DRAEM_BTS/assets/99871109/c985c7a8-da2e-4096-88ca-be21e5d9916b)

Figure 4. Simulated anomaly generation process. The binary anomaly mask Ma is generated from Perlin noise P . The anomalous regions are sampled from A according to Ma and placed on the anomaly free image I to generate the anomalous image $I_a$.

DRÃ†Mì€ ëŒ€ìƒ ì˜ì—­ì˜ ì‹¤ì œ ì´ìƒ í˜„ìƒì„ í˜„ì‹¤ì ìœ¼ë¡œ ë°˜ì˜í•˜ê¸° ìœ„í•´ ì‹œë®¬ë ˆì´ì…˜ì„ ìš”êµ¬í•˜ì§€ ì•Šê³ , ë§‰ ë¶„í¬ê°€ ëë‚œ ëª¨ì–‘ì„ ìƒì„±í•˜ì—¬ ì •ìƒìœ¼ë¡œë¶€í„°ì˜ í¸ì°¨ë¥¼ í†µí•´ ì´ìƒ í˜„ìƒì„ ì¸ì‹í•  ìˆ˜ ìˆëŠ” ì ì ˆí•œ ê±°ë¦¬ í•¨ìˆ˜ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.

- `ì‹œë®¬ë ˆì´ì…˜ì„ ìš”êµ¬ì•ˆí•¨ ì ì ˆí•œ ê±°ë¦¬ í•¨ìˆ˜ë¥¼ í•™ìŠµí• `
- `ì •ìƒìœ¼ë¡œë¶€í„°ì˜ í¸ì°¨ë¥¼ í†µí•´ ì´ìƒ í˜„ìƒì„ ì¸ì‹í•  ìˆ˜ ìˆìŒ`

A noise image is generated by `a Perlin noise` generator to capture a variety of anomaly shapes (Figure 4, P ) and binarized by `a threshold sampled uniformly at random` (Figure 4, Ma) into an anomaly map $M_a$.

<aside>
ğŸ’¡ ë‹¤ì–‘í•œ anomaly shapeì„ í¬ì°©í•˜ê¸° ìœ„í•´ Perlin noise generator ì‚¬ìš©

$M_a$ ëŠ” ë¬´ì‘ìœ„ë¡œ ê· ì¼í•˜ê²Œ ìƒ˜í”Œë§ëœ threshold ë¡œ ì¸í•´ ì´ì§„í™”ë¨

</aside>

The anomaly texture source image A is sampled from an anomaly source image dataset which is `unrelated to the input image distribution`

Â {*posterize, sharpness, solarize, equalize, brightness change, color change, auto-contrast*} ì¤‘ 3ê°œê°€ ëœë¤ìœ¼ë¡œ ì ìš©ë˜ì–´ Augmentation ëœë‹¤.

ì´ë ‡ê²Œ Augmented ëœ texture image $A$ëŠ” the anomaly map $M_a$ ì— ë§ˆìŠ¤í‚¹ ëœ í›„ $I$ ìœ„ì— í•©ì„±ëœë‹¤. <br>
= $I_a$
![Untitled 9](https://github.com/CodeofO/DRAEM_BTS/assets/99871109/dcac682c-25e6-4362-8992-73bbe278493f)

| $\overline{M}_a$ | inverse of $M_a$ |
| --- | --- |
| $\odot$ | the element-wise multiplication operation  |
| $\beta$ | the opacity parameter in blending.<br> sampled uniforms from an interval , $i.e., \beta \in [0.1, 1.0]$ |

## 3.4 Surface anomaly localization and detection
![Untitled 10](https://github.com/CodeofO/DRAEM_BTS/assets/99871109/5c30e04a-6879-4123-bf91-2239704b0b0a)


1. **Local Average Pooling**
    
    $M_o$ is smoothed by a mean filter convolution layer `to aggregate the local anomaly response information.`
    
2. **Global max pooling**
    
    
3. **Compute anomaly score map**
    
    The final image-level anomaly score $\eta$ is computed by taking the maximum value of the smoothed anomaly score map:
    ![Untitled 11](https://github.com/CodeofO/DRAEM_BTS/assets/99871109/2768cfd8-248a-4c04-bf12-a2153c96d65f)

        
    | $f_{(s_f \times s_f)}$ | a mean filter of size $s_f \times s_f$ <br> = Local Average Pooling ë ˆì´ì–´ì˜ í•„í„° í¬ê¸° |
    | --- | --- |
    | $*$ | the convolution operator  |
        
    ```python
    out_mask_averaged = torch.nn.functional.avg_pool2d(out_mask_sm[: ,1: ,: ,:], 21, stride=1,
                                                     padding=21 // 2).cpu().detach().numpy()
    image_score = np.max(out_mask_averaged)
    
    anomaly_score_prediction.append(image_score)
    ```
    
    Threshold ëŠ” ìš°ë¦¬ê°€ ì •ì˜í•´ì•¼ í•¨
    

<aside>
ğŸ’¡ ì—¬ê¸°ê¹Œì§€ Architecture ë¥¼ ê°„ë‹¨í•˜ê²Œ ì •ë¦¬í•˜ë©´

1. Making artificial anomalies image
    - a Perlin noise
    - binarized by a threshold sampled uniformly at random
    
2. The reconstructive Sub network
    
    ì¸ê³µì ìœ¼ë¡œ ë§Œë“  anomalies imageë¥¼ anomaly-free imageë¡œ ë³µì›ì‹œí‚¤ë„ë¡ í•™ìŠµ
    
3. The discriminative sub-network
    
    anomaly detection mask, $M_o$ ë¥¼ ì¶œë ¥í•˜ë„ë¡ í•™ìŠµ
    
4. Surface anomaly localization and detection
    
    discriminative networkì—ì„œ ì¶œë ¥ëœ $M_o$ ê°€ 2ê°œì˜ Layer ê±°ì¹œ í›„ anomaly score ì‚°ì¶œ
    
</aside>

# 4. Experiments
![Untitled 12](https://github.com/CodeofO/DRAEM_BTS/assets/99871109/829782f8-f548-421f-9e3f-a6fa5937c4c1)

Figure 8. Qualitative examples. The original image, the anomaly map overlay, the anomaly map and the ground truth map are shown.
